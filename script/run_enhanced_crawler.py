#!/usr/bin/env python3
"""
Run script for Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ Enhanced Crawler
Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹å¢å¼ºçˆ¬è™«è¿è¡Œè„šæœ¬
"""

import os
import sys
import time
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦å®‰è£…"""
    required_packages = [
        ('requests', 'requests'),
        ('bs4', 'beautifulsoup4'),  # ä¿®å¤å¯¼å…¥åç§°
        ('openai', 'openai'),
        ('dotenv', 'python-dotenv')
    ]
    
    missing_packages = []
    for import_name, package_name in required_packages:
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print("âŒ Missing required packages:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\nğŸ’¡ Install them with:")
        print(f"   pip install {' '.join(missing_packages)}")
        return False
    
    print("âœ… All required packages are installed")
    return True

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("\nğŸ” Checking environment configuration...")
    
    # æ£€æŸ¥.envæ–‡ä»¶
    env_file = Path(__file__).parent.parent / '.env'
    if env_file.exists():
        print("âœ… .env file found")
        
        # æ£€æŸ¥OpenAI API key
        from dotenv import load_dotenv
        load_dotenv(env_file)
        
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key and api_key != 'your_openai_api_key_here':
            print("âœ… OpenAI API key is set")
            return True
        else:
            print("âš ï¸  OpenAI API key not properly configured")
            print("   Please set OPENAI_API_KEY in your .env file")
            return False
    else:
        print("âŒ .env file not found")
        print("   Please create a .env file with your OpenAI API key")
        return False

def test_config():
    """æµ‹è¯•é…ç½®æ–‡ä»¶"""
    print("\nğŸ”§ Testing crawler configuration...")
    
    try:
        from crawler_config import CrawlerConfig
        
        config = CrawlerConfig()
        validation = config.validate_config()
        
        all_valid = True
        for key, value in validation.items():
            status = "âœ…" if value else "âŒ"
            print(f"{status} {key}: {value}")
            if not value:
                all_valid = False
        
        if all_valid:
            print("âœ… Configuration validation passed")
            return True
        else:
            print("âŒ Configuration validation failed")
            return False
            
    except Exception as e:
        print(f"âŒ Error testing configuration: {e}")
        return False

def run_crawler():
    """è¿è¡Œçˆ¬è™«"""
    print("\nğŸš€ Starting enhanced crawler...")
    
    try:
        from enhanced_crawler import YahooNewsCrawler
        
        # è·å–API key
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = YahooNewsCrawler(api_key)
        
        # è¿è¡Œå®Œæ•´æµç¨‹
        start_time = time.time()
        result = crawler.run_full_pipeline()
        end_time = time.time()
        
        if result:
            print(f"\nğŸ‰ Success! Dataset generation completed in {end_time - start_time:.2f} seconds")
            print(f"ğŸ“ Dataset saved to: {result}")
            
            # æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡
            import json
            with open(result, 'r', encoding='utf-8') as f:
                dataset = json.load(f)
            
            print(f"\nğŸ“Š Dataset Statistics:")
            print(f"   Total entries: {len(dataset)}")
            print(f"   File size: {os.path.getsize(result) / 1024:.2f} KB")
            print(f"   Output directory: {crawler.output_dir}")
            
            return True
        else:
            print("\nâŒ Failed to generate dataset")
            return False
            
    except Exception as e:
        print(f"âŒ Error running crawler: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ Enhanced Crawler - Test Runner")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return
    
    # 2. æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # 3. æµ‹è¯•é…ç½®
    if not test_config():
        return
    
    # 4. è¿è¡Œçˆ¬è™«
    success = run_crawler()
    
    if success:
        print("\nğŸŠ All tests passed! Enhanced crawler is working correctly.")
        print("\nğŸ“ Next steps:")
        print("   1. Check the generated dataset in 'yahoo_news_dataset' folder")
        print("   2. Review the LLM-generated answers")
        print("   3. Customize queries in 'crawler_config.py' if needed")
        print("   4. Integrate with your RAG system")
    else:
        print("\nâŒ Some tests failed. Please check the error messages above.")

if __name__ == "__main__":
    main()
