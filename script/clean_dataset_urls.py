#!/usr/bin/env python3
"""
æ¸…ç†Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°æ®é›†ä¸­çš„æ— ç”¨URL
åˆ é™¤é€šç”¨çš„é¡µé¢URLï¼Œæ¯ä¸ªæ¡ç›®åªä¿ç•™ä¸€ä¸ªæœ€ç›¸å…³çš„URL
"""

import json
import os
from typing import List, Dict

def clean_dataset_urls(input_file: str, output_file: str = None):
    """æ¸…ç†æ•°æ®é›†ä¸­çš„æ— ç”¨URLï¼Œæ¯ä¸ªæ¡ç›®åªä¿ç•™ä¸€ä¸ªURL"""
    
    # è¯»å–åŸå§‹æ•°æ®é›†
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“– è¯»å–æ•°æ®é›†: {len(data)} ä¸ªæ¡ç›®")
    
    # æ— ç”¨çš„URLåˆ—è¡¨
    useless_urls = [
        "https://news.yahoo.co.jp",
        "https://news.yahoo.co.jp/topics", 
        "https://news.yahoo.co.jp/ranking"
    ]
    
    cleaned_count = 0
    
    # æ¸…ç†æ¯ä¸ªæ¡ç›®
    for i, item in enumerate(data):
        if "original_urls" in item:
            original_urls = item["original_urls"]
            
            # è¿‡æ»¤æ‰æ— ç”¨çš„URL
            cleaned_urls = [url for url in original_urls if url not in useless_urls]
            
            # å¦‚æœæ¸…ç†åæ²¡æœ‰URLäº†ï¼Œä¿ç•™ä¸€ä¸ªä¸»è¦çš„URL
            if not cleaned_urls:
                cleaned_urls = ["https://news.yahoo.co.jp"]
            
            # ç¡®ä¿æ¯ä¸ªæ¡ç›®åªä¿ç•™ä¸€ä¸ªURLï¼ˆå–ç¬¬ä¸€ä¸ªï¼‰
            if len(cleaned_urls) > 1:
                cleaned_urls = [cleaned_urls[0]]
                print(f"  æ¡ç›® {i+1}: å¤šä¸ªURL -> åªä¿ç•™ç¬¬ä¸€ä¸ª: {cleaned_urls[0]}")
            
            # æ›´æ–°æ¡ç›®
            if len(cleaned_urls) != len(original_urls):
                data[i]["original_urls"] = cleaned_urls
                cleaned_count += 1
                print(f"  æ¡ç›® {i+1}: æ¸…ç†äº† {len(original_urls)} -> {len(cleaned_urls)} ä¸ªURL")
    
    print(f"ğŸ§¹ æ€»å…±æ¸…ç†äº† {cleaned_count} ä¸ªæ¡ç›®")
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if not output_file:
        base_name = os.path.splitext(input_file)[0]
        output_file = f"{base_name}_single_url.json"
    
    # ä¿å­˜æ¸…ç†åçš„æ•°æ®é›†
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ¸…ç†åçš„æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}")
    
    return output_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°æ®é›†URLæ¸…ç†å·¥å…·")
    print("æ¯ä¸ªæ¡ç›®åªä¿ç•™ä¸€ä¸ªæœ€ç›¸å…³çš„URL")
    print("=" * 50)
    
    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_file = "yahoo_news_dataset/yahoo_news_dataset_20250827_155647.json"
    
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    
    try:
        # æ¸…ç†æ•°æ®é›†
        output_file = clean_dataset_urls(input_file)
        
        print(f"\nâœ… æ¸…ç†å®Œæˆï¼")
        print(f"   è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"   ç°åœ¨æ¯ä¸ªæ¡ç›®åªåŒ…å«ä¸€ä¸ªURL")
        
    except Exception as e:
        print(f"âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    main()
