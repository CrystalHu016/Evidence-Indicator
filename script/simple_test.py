#!/usr/bin/env python3
"""
Simple test script for basic article parsing
ç®€å•æµ‹è¯•è„šæœ¬ - æµ‹è¯•åŸºæœ¬æ–‡ç« è§£æåŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

def test_specific_article():
    """æµ‹è¯•ç‰¹å®šæ–‡ç« çš„è§£æ"""
    print("ğŸ“° Testing Specific Article Parsing")
    print("=" * 50)
    
    try:
        from enhanced_crawler import YahooNewsCrawler
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âŒ OpenAI API key not found")
            return
        
        crawler = YahooNewsCrawler(api_key)
        
        # æµ‹è¯•è§£æç‰¹å®šæ–‡ç« 
        test_url = "https://news.yahoo.co.jp/articles/50e410b05cd15dd4acc318a5673ea3169189267c"
        
        print(f"ğŸ” Parsing article: {test_url}")
        
        article_content = crawler.extract_article_content(test_url)
        
        if article_content:
            print(f"âœ… Article parsed successfully!")
            print(f"ğŸ“ Title: {article_content['title']}")
            print(f"ğŸ“Š Word count: {article_content['word_count']}")
            print(f"â° Publish time: {article_content['publish_time']}")
            print(f"ğŸ“„ Content preview: {article_content['content'][:500]}...")
            
            # æµ‹è¯•LLMå›ç­”ç”Ÿæˆ
            print(f"\nğŸ¤– Testing LLM answer generation...")
            user_query = "AIã§ç—…é™¢ã®æ¥­å‹™åŠ¹ç‡åŒ–å®Ÿä¾‹ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
            
            answer = crawler.generate_llm_answer(user_query, str(article_content))
            
            if answer:
                print(f"âœ… LLM answer generated:")
                print(f"ğŸ“ {answer}")
            else:
                print("âŒ Failed to generate LLM answer")
                
        else:
            print("âŒ Failed to parse article")
        
    except Exception as e:
        print(f"âŒ Error during article parsing: {e}")
        import traceback
        traceback.print_exc()

def test_category_page():
    """æµ‹è¯•åˆ†ç±»é¡µé¢è§£æ"""
    print("\nğŸ“‚ Testing Category Page Parsing")
    print("=" * 50)
    
    try:
        from enhanced_crawler import YahooNewsCrawler
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âŒ OpenAI API key not found")
            return
        
        crawler = YahooNewsCrawler(api_key)
        
        # æµ‹è¯•ITåˆ†ç±»é¡µé¢
        test_url = "https://news.yahoo.co.jp/categories/it"
        
        print(f"ğŸ” Parsing category page: {test_url}")
        
        html = crawler.get_page_content(test_url)
        if html:
            articles = crawler.parse_category_content(html, 'it')
            print(f"âœ… Found {len(articles)} articles in IT category")
            
            if articles:
                print("ğŸ“° Sample articles:")
                for i, article in enumerate(articles[:3], 1):
                    print(f"  {i}. {article['title']}")
                    print(f"     URL: {article['url']}")
        else:
            print("âŒ Failed to fetch category page")
        
    except Exception as e:
        print(f"âŒ Error during category page parsing: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ Simple Test")
    print("=" * 60)
    
    # æµ‹è¯•ç‰¹å®šæ–‡ç« è§£æ
    test_specific_article()
    
    # æµ‹è¯•åˆ†ç±»é¡µé¢è§£æ
    test_category_page()
    
    print("\nğŸ‰ Simple test completed!")

if __name__ == "__main__":
    main()
