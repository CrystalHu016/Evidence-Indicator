#!/usr/bin/env python3
"""
Test script for article search and question answering functionality
æµ‹è¯•æ–‡ç« æœç´¢å’Œé—®é¢˜å›ç­”åŠŸèƒ½çš„è„šæœ¬
"""

import os
import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))

def test_article_search():
    """æµ‹è¯•æ–‡ç« æœç´¢åŠŸèƒ½"""
    print("ğŸ” Testing Article Search Functionality")
    print("=" * 50)
    
    try:
        from enhanced_crawler import YahooNewsCrawler
        from dotenv import load_dotenv
        
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âŒ OpenAI API key not found")
            return
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = YahooNewsCrawler(api_key)
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "AIã§ç—…é™¢ã®æ¥­å‹™åŠ¹ç‡åŒ–å®Ÿä¾‹",
            "å¯Œå£«é€šã®AIã‚·ã‚¹ãƒ†ãƒ ",
            "åŒ»ç™‚AIã®æœ€æ–°æŠ€è¡“",
            "ç—…é™¢æ¥­å‹™ã®è‡ªå‹•åŒ–",
            "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŒ»ç™‚å¿œç”¨"
        ]
        
        for query in test_queries:
            print(f"\nğŸ¯ Testing query: {query}")
            print("-" * 40)
            
            # æœç´¢ç›¸å…³æ–‡ç« 
            result = crawler.answer_question_with_articles(query)
            
            print(f"ğŸ“ Answer: {result['answer'][:200]}...")
            print(f"ğŸ¯ Confidence: {result['confidence']:.2f}")
            print(f"ğŸ“Š Total articles found: {result['total_articles_found']}")
            
            if result['sources']:
                print("ğŸ“š Top sources:")
                for i, source in enumerate(result['sources'][:3], 1):
                    print(f"  {i}. {source['title']}")
                    print(f"     URL: {source['url']}")
                    print(f"     Score: {source['relevance_score']:.1f}")
                    print(f"     Category: {source['source']}")
            else:
                print("âŒ No sources found")
            
            print()
        
        print("âœ… Article search test completed!")
        
    except Exception as e:
        print(f"âŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()

def test_specific_article():
    """æµ‹è¯•ç‰¹å®šæ–‡ç« çš„è§£æ"""
    print("\nğŸ“° Testing Specific Article Parsing")
    print("=" * 50)
    
    try:
        from enhanced_crawler import YahooNewsCrawler
        from dotenv import load_dotenv
        
        load_dotenv()
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("âŒ OpenAI API key not found")
            return
        
        crawler = YahooNewsCrawler(api_key)
        
        # æµ‹è¯•è§£æç‰¹å®šæ–‡ç« 
        test_url = "https://news.yahoo.co.jp/articles/50e410b05cd15dd4acc318a5673ea3169189267c"
        
        print(f"ğŸ” Parsing article: {test_url}")
        
        article_content = crawler.extract_article_content(test_url)
        
        if article_content:
            print(f"âœ… Article parsed successfully!")
            print(f"ğŸ“ Title: {article_content['title']}")
            print(f"ğŸ“Š Word count: {article_content['word_count']}")
            print(f"â° Publish time: {article_content['publish_time']}")
            print(f"ğŸ“„ Content preview: {article_content['content'][:300]}...")
        else:
            print("âŒ Failed to parse article")
        
    except Exception as e:
        print(f"âŒ Error during article parsing: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ Article Search Test")
    print("=" * 60)
    
    # æµ‹è¯•æ–‡ç« æœç´¢åŠŸèƒ½
    test_article_search()
    
    # æµ‹è¯•ç‰¹å®šæ–‡ç« è§£æ
    test_specific_article()
    
    print("\nğŸ‰ All tests completed!")

if __name__ == "__main__":
    main()
